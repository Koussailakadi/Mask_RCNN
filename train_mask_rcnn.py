# -*- coding: utf-8 -*-
"""Train_Mask_RCNN_(DEMO)(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/pysource7/utilities/blob/master/Train_Mask_RCNN_(DEMO).ipynb

## **1. Installation**

Load your dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
!pip install --upgrade h5py==2.10.0
!wget https://pysource.com/extra_files/Mask_RCNN_basic_1.zip
!unzip Mask_RCNN_basic_1.zip
# %matplotlib inline

import os
import sys
sys.path.append("/content/Mask_RCNN/")
print(os.getcwd())
print(os.listdir(os.getcwd()))
from mrcnn import *
from mrcnn.m_rcnn import *

"""## **2. Image Dataset**

Load your annotated dataset

"""

# Extract Images
images_path = "with_cracks.zip"
annotations_path = "annotations_coco.json"

extract_images(os.path.join("/content/",images_path), "/content/dataset")

dataset_train = load_image_dataset(os.path.join("/content/", annotations_path), "/content/dataset", "train")
dataset_val = load_image_dataset(os.path.join("/content/", annotations_path), "/content/dataset", "val")
class_number = dataset_train.count_classes()
print('Train: %d' % len(dataset_train.image_ids))
print('Validation: %d' % len(dataset_val.image_ids))
print("Classes: {}".format(class_number))

# Load image samples
display_image_samples(dataset_train)

# Load image samples
display_image_samples(dataset_val)

"""##**3. Training**

Train Mask RCNN on your custom Dataset.
"""

class CustomConfig(Config):
    """Configuration for training on the custom  dataset.
    Derives from the base Config class and overrides some values.
    """
    """# Give the configuration a recognizable name
    NAME = "object"

    IMAGES_PER_GPU = 1

    NUM_CLASSES = 1 + 2  # Background + Car and truck

    # Number of training steps per epoch
    STEPS_PER_EPOCH = 10

    # Skip detections with < 90% confidence
    DETECTION_MIN_CONFIDENCE = 0.9"""

    # Give the configuration a recognizable name
    NAME = "object"

    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each
    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).
    GPU_COUNT = 1
    IMAGES_PER_GPU = 4

    # Number of classes
    NUM_CLASSES = 1 + 2

    # Use small images for faster training. Set the limits of the small side
    # the large side, and that determines the image shape.
    IMAGE_MIN_DIM = 256
    IMAGE_MAX_DIM = 384

    # channel of images: 
    # IMAGE_CHANNEL_COUNT = 1

    # Use smaller anchors because our image and objects are small
    # RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels

    # Reduce training ROIs per image because the images are small and have
    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.
    # TRAIN_ROIS_PER_IMAGE = 32

    # Use a small epoch since the data is simple
    STEPS_PER_EPOCH = 500

    # use small validation steps since the epoch is small
    VALIDATION_STEPS = 5

    DETECTION_MIN_CONFIDENCE = 0.9

# Load Configuration
config = CustomConfig()
config.display()
model = load_training_model(config)

# Start Training
# This operation might take a long time.
train_head(model, dataset_train, dataset_val, config)

"""## **4. Detection (test your model on a random image)**"""

# Load Test Model
# The latest trained model will be loaded
# test_model, inference_config = load_test_model(class_number)
#LOAD MODEL. Create model in inference mode
model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=config)

# Test on a random image
test_random_image(model, dataset_val, config)

